{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML-CVAE.ipynb","provenance":[{"file_id":"19c7OC2g1zdIH5Aflf8_3G8vvb9kreqkM","timestamp":1607810315634}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"6YC0rvQV4OE5"},"source":["from IPython import display\n","\n","import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import PIL\n","import tensorflow as tf\n","import tensorflow_probability as tfp\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xtPULTr54kpb"},"source":["#load the MNIST images dataset\n","(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YJSlwlws4ms-"},"source":["def preprocess(images):\n","  # reshape the images to 28x28x1 and normalize\n","  images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\n","\n","  # return images which satisfy condition\n","  return np.where(images > .5, 1.0, 0.0).astype('float32')\n","\n","train_images = preprocess(train_images)\n","test_images = preprocess(test_images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9THXEbE4or1"},"source":["train_size = 60000\n","batch_size = 64\n","test_size = 10000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6O5LRlVl4ssP"},"source":["# create batches of the data and shuffle to prevent any biases while training\n","\n","train_dataset = (tf.data.Dataset.from_tensor_slices(train_images)\n","                 .shuffle(train_size).batch(batch_size))\n","test_dataset = (tf.data.Dataset.from_tensor_slices(test_images)\n","                .shuffle(test_size).batch(batch_size))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FElp2NYc4uuR"},"source":["\n","# create a class for the convolutional variational autoencoder which is derived from the tf.keras.Model class\n","class CVAE_Model(tf.keras.Model):\n","\n","  def __init__(self, latent_dim):\n","    super(CVAE_Model, self).__init__()\n","    self.latent_dim = latent_dim\n","    self.encoder = tf.keras.Sequential(\n","        [\n","            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n","            tf.keras.layers.Conv2D(\n","                filters=64, kernel_size=4, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.Conv2D(\n","                filters=64, kernel_size=4, strides=(2, 2), activation='relu'),\n","            tf.keras.layers.Conv2D(\n","                filters=64, kernel_size=4, strides=(1, 1), activation='relu'),\n","            tf.keras.layers.Flatten(),\n","            tf.keras.layers.Dense(latent_dim + latent_dim),\n","        ]\n","    )\n","\n","    self.decoder = tf.keras.Sequential(\n","        [\n","            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n","            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n","            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=64, kernel_size=4, strides=2, padding='same',\n","                activation='relu'),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=64, kernel_size=4, strides=2, padding='same',\n","                activation='relu'),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=64, kernel_size=4, strides=1, padding='same',\n","                activation='relu'),\n","            tf.keras.layers.Conv2DTranspose(\n","                filters=1, kernel_size=3, strides=1, padding='same'),\n","        ]\n","    )\n","\n","  def encode(self, x):\n","    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n","    return mean, logvar\n","\n","  def decode(self, z, apply_sigmoid=False):\n","    logits = self.decoder(z)\n","    if apply_sigmoid:\n","      probs = tf.sigmoid(logits)\n","      return probs\n","    return logits\n","  \n","  def reparameterize(self, mean, logvar):\n","    eps = tf.random.normal(shape=mean.shape)\n","    return eps * tf.exp(logvar * .5) + mean\n","\n","  @tf.function\n","  def sample(self, eps=None):\n","    if eps is None:\n","      eps = tf.random.normal(shape=(100, self.latent_dim))\n","    return self.decode(eps, apply_sigmoid=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L25XuD_44xz5"},"source":["optimizer = tf.keras.optimizers.Adam(1e-4)\n","\n","# Probability density function with log normal\n","def pdf_log_normal(sample, mean, logvar, raxis=1):\n","  log2pi = tf.math.log(2. * np.pi)\n","  return tf.reduce_sum(\n","      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n","      axis=raxis)\n","\n","\n","def compute_loss(model, x):\n","  mean, logvar = model.encode(x)\n","  z = model.reparameterize(mean, logvar)\n","  x_logit = model.decode(z)\n","  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n","  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n","  logpz = pdf_log_normal(z, 0., 0.)\n","  logqz_x = pdf_log_normal(z, mean, logvar)\n","  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n","\n","\n","@tf.function\n","def train_step(model, x, optimizer):\n","  with tf.GradientTape() as tape:\n","    loss = compute_loss(model, x)\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3bO-93Gd414W"},"source":["epochs = 700\n","latent_dim = 2\n","num_examples_to_generate = 16\n","\n","random_vector_for_generation = tf.random.normal(\n","    shape=[num_examples_to_generate, latent_dim])\n","model = CVAE_Model(latent_dim)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOoEmYRb43rY"},"source":["def generate_and_save_images(model, epoch, test_sample):\n","  mean, logvar = model.encode(test_sample)\n","  z = model.reparameterize(mean, logvar)\n","  predictions = model.sample(z)\n","  fig = plt.figure(figsize=(4, 4))\n","\n","  for i in range(predictions.shape[0]):\n","    plt.subplot(4, 4, i + 1)\n","    plt.imshow(predictions[i, :, :, 0], cmap='gray')\n","    plt.axis('off')\n","\n","  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gAswqcVF45Yh"},"source":["# Pick a sample of the test set for generating output images\n","assert batch_size >= num_examples_to_generate\n","for test_batch in test_dataset.take(1):\n","  test_sample = test_batch[0:num_examples_to_generate, :, :, :]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iwcmlca75Bq6"},"source":["generate_and_save_images(model, 0, test_sample)\n","\n","for epoch in range(1, epochs + 1):\n","  start_time = time.time()\n","  for train_x in train_dataset:\n","    train_step(model, train_x, optimizer)\n","  end_time = time.time()\n","\n","  loss = tf.keras.metrics.Mean()\n","  for test_x in test_dataset:\n","    loss(compute_loss(model, test_x))\n","  elbo = -loss.result()\n","  display.clear_output(wait=False)\n","  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n","        .format(epoch, elbo, end_time - start_time))\n","  generate_and_save_images(model, epoch, test_sample)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rYRV4zir5HLY"},"source":["def display_image(epoch_no):\n","  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L788ufJ55Hyb"},"source":["plt.imshow(display_image(epoch))\n","plt.axis('off')  # Display images"],"execution_count":null,"outputs":[]}]}